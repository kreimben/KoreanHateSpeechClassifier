{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Korean Hate Speech Classifier\n",
    "## Written by: [Jehwan Kim](github.com/kreimben)\n",
    "## Date: 19th Feb 2024\n",
    "## Referenced Paper: \n",
    "* [Convolutional Neural Networks for Sentence Classification](https://arxiv.org/abs/1408.5882)\n",
    "* [Cyclical Learning Rates for Training Neural Networks](https://arxiv.org/abs/1506.01186)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b85a589180c7304"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the word2vec model first,"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76142ca29aea3a03"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:27.671295300Z",
     "start_time": "2024-02-20T00:53:26.542602400Z"
    }
   },
   "id": "95ba83ff602bf2ae",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### And then, load labeled data using pandas"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc778d92bb73c7c1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dev_df = pd.read_csv('./labeled/dev.tsv', sep='\\t')\n",
    "train_df = pd.read_csv('./labeled/train.tsv', sep='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:27.710304100Z",
     "start_time": "2024-02-20T00:53:27.671295300Z"
    }
   },
   "id": "483cddf9b1ef8ff5",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                            comments  contain_gender_bias  \\\n0  (현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...                False   \n1  ....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...                False   \n2  ...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...                False   \n3                 1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데                False   \n4  1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...                 True   \n\n     bias  hate  \n0  others  hate  \n1    none  none  \n2    none  hate  \n3    none  none  \n4  gender  hate  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comments</th>\n      <th>contain_gender_bias</th>\n      <th>bias</th>\n      <th>hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...</td>\n      <td>False</td>\n      <td>others</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...</td>\n      <td>False</td>\n      <td>none</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...</td>\n      <td>False</td>\n      <td>none</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데</td>\n      <td>False</td>\n      <td>none</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...</td>\n      <td>True</td>\n      <td>gender</td>\n      <td>hate</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:27.732309100Z",
     "start_time": "2024-02-20T00:53:27.703302700Z"
    }
   },
   "id": "957b5d894af019aa",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                            comments  contain_gender_bias  \\\n0                        송중기 시대극은 믿고본다. 첫회 신선하고 좋았다.                False   \n1                                            지현우 나쁜놈                False   \n2         알바쓰고많이만들면되지 돈욕심없으면골목식당왜나온겨 기댕기게나하고 산에가서팔어라                False   \n3                                   설마 ㅈ 현정 작가 아니지??                 True   \n4  이미자씨 송혜교씨 돈이 그리 많으면 탈세말고 그돈으로 평소에 불우이웃에게 기부도 좀...                False   \n\n     bias       hate  \n0    none       none  \n1    none  offensive  \n2    none       hate  \n3  gender       hate  \n4    none  offensive  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comments</th>\n      <th>contain_gender_bias</th>\n      <th>bias</th>\n      <th>hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>송중기 시대극은 믿고본다. 첫회 신선하고 좋았다.</td>\n      <td>False</td>\n      <td>none</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>지현우 나쁜놈</td>\n      <td>False</td>\n      <td>none</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>알바쓰고많이만들면되지 돈욕심없으면골목식당왜나온겨 기댕기게나하고 산에가서팔어라</td>\n      <td>False</td>\n      <td>none</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>설마 ㅈ 현정 작가 아니지??</td>\n      <td>True</td>\n      <td>gender</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>이미자씨 송혜교씨 돈이 그리 많으면 탈세말고 그돈으로 평소에 불우이웃에게 기부도 좀...</td>\n      <td>False</td>\n      <td>none</td>\n      <td>offensive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:27.757819700Z",
     "start_time": "2024-02-20T00:53:27.720306400Z"
    }
   },
   "id": "6998e4faa8a15643",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### In `hate` column, `offensive`, `none`, `hate`.\n",
    "### In `contain_gender_bias` column, `True`, `False`.\n",
    "### In `bias` column, `none`, `gender`, `others`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f3074856f112f7c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                               comments  contain_gender_bias  \\\n3726  사람에겐 싫어할 권리도 있다 왜 모든이가 널 이해해줘야 하는거냐? LGBT를 싫어할...                 True   \n4800                            약태환. . 이미 내 머리속에선 지워졌다.                False   \n6683              자연미인도 아닌게... 네이버일마들 자꾸 띄우는겨? 지겹네 아오~~                False   \n1781                꼴랑 이백 ,삼백?너무 한거 아녀?이억,삼억 해도 모자랄판인데!                False   \n2133  너무 안타깝네요....삼가 고인의 명복을 빕니다하늘나라에서 부모님과 아이를 잘 지켜...                False   \n\n        bias       hate  \n3726  gender       hate  \n4800    none  offensive  \n6683    none       hate  \n1781    none       none  \n2133    none       none  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comments</th>\n      <th>contain_gender_bias</th>\n      <th>bias</th>\n      <th>hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3726</th>\n      <td>사람에겐 싫어할 권리도 있다 왜 모든이가 널 이해해줘야 하는거냐? LGBT를 싫어할...</td>\n      <td>True</td>\n      <td>gender</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>4800</th>\n      <td>약태환. . 이미 내 머리속에선 지워졌다.</td>\n      <td>False</td>\n      <td>none</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>6683</th>\n      <td>자연미인도 아닌게... 네이버일마들 자꾸 띄우는겨? 지겹네 아오~~</td>\n      <td>False</td>\n      <td>none</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>1781</th>\n      <td>꼴랑 이백 ,삼백?너무 한거 아녀?이억,삼억 해도 모자랄판인데!</td>\n      <td>False</td>\n      <td>none</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>2133</th>\n      <td>너무 안타깝네요....삼가 고인의 명복을 빕니다하늘나라에서 부모님과 아이를 잘 지켜...</td>\n      <td>False</td>\n      <td>none</td>\n      <td>none</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine train and dev data.\n",
    "df = pd.concat([dev_df, train_df], ignore_index=True)\n",
    "df.sample(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:27.816833400Z",
     "start_time": "2024-02-20T00:53:27.735309800Z"
    }
   },
   "id": "57a62ec519832594",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(hate\n none         3646\n offensive    2688\n hate         2033\n Name: count, dtype: int64,\n contain_gender_bias\n False    404\n True      67\n Name: count, dtype: int64,\n bias\n none      342\n gender     67\n others     62\n Name: count, dtype: int64)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.hate.value_counts(), dev_df.contain_gender_bias.value_counts(), dev_df.bias.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:27.881353800Z",
     "start_time": "2024-02-20T00:53:27.750314300Z"
    }
   },
   "id": "adc2696d1f6809b2",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load words data and tokeniser from past project."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48640b0cad2eddfe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('tokenizer.pkl', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "with open('words.pkl', 'rb') as handle:\n",
    "    words = pickle.load(handle)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:29.236519100Z",
     "start_time": "2024-02-20T00:53:27.764822Z"
    }
   },
   "id": "c309aefe176e427a",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from utils.stopwords import STOP_WORDS\n",
    "\n",
    "\n",
    "def tokenize(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    preprocess = lambda x: [w for w in x if w not in STOP_WORDS]\n",
    "    return preprocess(tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:29.238519300Z",
     "start_time": "2024-02-20T00:53:29.222515800Z"
    }
   },
   "id": "3d3dbea551c4ae89",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "('개oooo새oooo끼가 19살? 장난하는것도아니구. 먹는 음식 가지고 장난좀 하지 말자.',\n ['개oooo새oooo',\n  '끼가',\n  '19살',\n  '?',\n  '장난하는것',\n  '구.',\n  '먹는',\n  '음식',\n  '가지고',\n  '장난',\n  '말자.'])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df.sample(1).comments.values[0]\n",
    "\n",
    "sample, tokenize(sample)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:29.282034200Z",
     "start_time": "2024-02-20T00:53:29.239519200Z"
    }
   },
   "id": "32c7deac9d238855",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksid\\AppData\\Local\\Temp\\ipykernel_14504\\1445675357.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['hate'] = df['hate'].replace(['none', 'offensive', 'hate'], [0, 1, 1])\n",
      "C:\\Users\\aksid\\AppData\\Local\\Temp\\ipykernel_14504\\1445675357.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['contain_gender_bias'] = df['contain_gender_bias'].replace([True, False], [1, 0])\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                            comments  contain_gender_bias  \\\n0                        송중기 시대극은 믿고본다. 첫회 신선하고 좋았다.                    0   \n1                                            지현우 나쁜놈                    0   \n2         알바쓰고많이만들면되지 돈욕심없으면골목식당왜나온겨 기댕기게나하고 산에가서팔어라                    0   \n3                                   설마 ㅈ 현정 작가 아니지??                    1   \n4  이미자씨 송혜교씨 돈이 그리 많으면 탈세말고 그돈으로 평소에 불우이웃에게 기부도 좀...                    0   \n\n     bias  hate                                             tokens  \n0    none     0              [송중기, 시대, 극은, 믿고, 본다., 첫회, 신선, 았다, .]  \n1    none     1                                         [지현우, 나쁜놈]  \n2    none     1  [알바, 쓰고, 많이, 만들면, 되지, 돈, 욕심, 으면, 골목, 식당, 왜나온겨,...  \n3  gender     1                                    [ㅈ, 현정, 작가, ??]  \n4    none     1  [이미자, 송혜교, 돈이, 그리, 으면, 탈세, 말고, 그돈, 평소, 불우이웃, 기...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comments</th>\n      <th>contain_gender_bias</th>\n      <th>bias</th>\n      <th>hate</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>송중기 시대극은 믿고본다. 첫회 신선하고 좋았다.</td>\n      <td>0</td>\n      <td>none</td>\n      <td>0</td>\n      <td>[송중기, 시대, 극은, 믿고, 본다., 첫회, 신선, 았다, .]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>지현우 나쁜놈</td>\n      <td>0</td>\n      <td>none</td>\n      <td>1</td>\n      <td>[지현우, 나쁜놈]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>알바쓰고많이만들면되지 돈욕심없으면골목식당왜나온겨 기댕기게나하고 산에가서팔어라</td>\n      <td>0</td>\n      <td>none</td>\n      <td>1</td>\n      <td>[알바, 쓰고, 많이, 만들면, 되지, 돈, 욕심, 으면, 골목, 식당, 왜나온겨,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>설마 ㅈ 현정 작가 아니지??</td>\n      <td>1</td>\n      <td>gender</td>\n      <td>1</td>\n      <td>[ㅈ, 현정, 작가, ??]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>이미자씨 송혜교씨 돈이 그리 많으면 탈세말고 그돈으로 평소에 불우이웃에게 기부도 좀...</td>\n      <td>0</td>\n      <td>none</td>\n      <td>1</td>\n      <td>[이미자, 송혜교, 돈이, 그리, 으면, 탈세, 말고, 그돈, 평소, 불우이웃, 기...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = df['comments'].apply(tokenize)\n",
    "# 공격적인(offensive) 댓글 또한 혐오 데이터 셋으로 분류함.\n",
    "df['hate'] = df['hate'].replace(['none', 'offensive', 'hate'], [0, 1, 1])\n",
    "df['contain_gender_bias'] = df['contain_gender_bias'].replace([True, False], [1, 0])\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:30.345834500Z",
     "start_time": "2024-02-20T00:53:29.256524600Z"
    }
   },
   "id": "da709590362b1e96",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for sentence in df.tokens:\n",
    "    for word in sentence: vocab.add(word)\n",
    "\n",
    "# TODO: filter the stopwords\n",
    "vocab_size = len(vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:30.414053200Z",
     "start_time": "2024-02-20T00:53:30.334329300Z"
    }
   },
   "id": "b281c2177fdf376",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vectorise"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7ef7501882fb09f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('vectorizer.pkl', 'rb') as handle:\n",
    "    vectorizer = pickle.load(handle)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:30.960464700Z",
     "start_time": "2024-02-20T00:53:30.364845200Z"
    }
   },
   "id": "5b6238857638d8c2",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encoding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9a0973672e14a64"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0         [13834, 366, 55661, 671, 1342, 16079, 423, 432]\n1                                                  [6021]\n2       [750, 384, 2886, 332, 1898, 10604, 3279, 21690...\n3                               [1990, 1092, 75890, 9257]\n4       [84631, 533, 15596, 533, 454, 171, 779, 5641, ...\n                              ...                        \n8362                                        [2805, 11384]\n8363                       [2805, 7442, 3105, 3781, 3744]\n8364              [46019, 1577, 58, 591, 1505, 22957, 58]\n8365    [4232, 882, 75943, 769, 4678, 887, 22943, 4270...\n8366       [396, 1469, 1727, 36544, 1694, 30, 3644, 5144]\nName: encoding, Length: 8367, dtype: object"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['encoding'] = df['comments'].apply(vectorizer.encode_a_doc_to_list)\n",
    "df.encoding"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:31.626744700Z",
     "start_time": "2024-02-20T00:53:30.949360500Z"
    }
   },
   "id": "ae2f4030b420969e",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate\n",
      "1    4721\n",
      "0    3646\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "(8367, 8367, True)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = df['encoding']\n",
    "y_data = df['hate']\n",
    "print(y_data.value_counts())\n",
    "len(X_data), len(y_data), len(X_data) == len(y_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:31.640748Z",
     "start_time": "2024-02-20T00:53:31.624744900Z"
    }
   },
   "id": "abc1b33996c85487",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "hate\n1    3824\n0    2953\nName: count, dtype: int64"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=.1, random_state=0, stratify=y_data)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=.1, random_state=0, stratify=y_train)\n",
    "\n",
    "y_train.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:31.697787300Z",
     "start_time": "2024-02-20T00:53:31.638748Z"
    }
   },
   "id": "aea73a715225d891",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공격적인(offensive) 댓글 또한 혐오 데이터 셋으로 분류함.\n",
      "--------훈련 데이터의 비율-----------\n",
      "혐오 댓글 = 56.426%\n",
      "일반 댓글 = 43.574%\n",
      "--------검증 데이터의 비율-----------\n",
      "혐오 댓글 = 56.441%\n",
      "일반 댓글 = 43.559%\n",
      "--------테스트 데이터의 비율-----------\n",
      "혐오 댓글 = 56.392%\n",
      "일반 댓글 = 43.608%\n"
     ]
    }
   ],
   "source": [
    "print('공격적인(offensive) 댓글 또한 혐오 데이터 셋으로 분류함.')\n",
    "print('--------훈련 데이터의 비율-----------')\n",
    "print(f'혐오 댓글 = {round(y_train.value_counts()[1] / len(y_train) * 100, 3)}%')\n",
    "print(f'일반 댓글 = {round(y_train.value_counts()[0] / len(y_train) * 100, 3)}%')\n",
    "print('--------검증 데이터의 비율-----------')\n",
    "print(f'혐오 댓글 = {round(y_valid.value_counts()[1] / len(y_valid) * 100, 3)}%')\n",
    "print(f'일반 댓글 = {round(y_valid.value_counts()[0] / len(y_valid) * 100, 3)}%')\n",
    "print('--------테스트 데이터의 비율-----------')\n",
    "print(f'혐오 댓글 = {round(y_test.value_counts()[1] / len(y_test) * 100, 3)}%')\n",
    "print(f'일반 댓글 = {round(y_test.value_counts()[0] / len(y_test) * 100, 3)}%')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:31.698787Z",
     "start_time": "2024-02-20T00:53:31.671781300Z"
    }
   },
   "id": "636c107f5616018a",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Padding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc3cc8cad19abafc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "댓글의 최대 길이 : 39\n",
      "댓글의 평균 길이 : 9.449018739855394\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('댓글의 최대 길이 :', max(len(review) for review in X_train))\n",
    "print('댓글의 평균 길이 :', sum(map(len, X_train)) / len(X_train))\n",
    "plt.hist([len(review) for review in X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:31.842834300Z",
     "start_time": "2024-02-20T00:53:31.687785Z"
    }
   },
   "id": "c9771b28e6e289d0",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "max_len = max(len(review) for review in X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:31.883348300Z",
     "start_time": "2024-02-20T00:53:31.831831400Z"
    }
   },
   "id": "5e299ce12a3f55b8",
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 길이가 길지 않아서 그냥 최대값 그대로 진행합니다. (패딩)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce876dd87ee220ea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def pad_sequences(sentences: [[int]], max_len: int) -> np.ndarray:\n",
    "    features = np.zeros((len(sentences), max_len), dtype=int)\n",
    "    for index, sentence in enumerate(sentences):\n",
    "        if len(sentence) != 0:\n",
    "            features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
    "    return features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:31.884348500Z",
     "start_time": "2024-02-20T00:53:31.847836Z"
    }
   },
   "id": "f31851242ee3396a",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 크기 : (6777, 39)\n",
      "검증 데이터의 크기 : (753, 39)\n",
      "테스트 데이터의 크기 : (837, 39)\n"
     ]
    }
   ],
   "source": [
    "padded_X_train = pad_sequences(X_train, max_len=max_len)\n",
    "padded_X_valid = pad_sequences(X_valid, max_len=max_len)\n",
    "padded_X_test = pad_sequences(X_test, max_len=max_len)\n",
    "\n",
    "print('훈련 데이터의 크기 :', padded_X_train.shape)\n",
    "print('검증 데이터의 크기 :', padded_X_valid.shape)\n",
    "print('테스트 데이터의 크기 :', padded_X_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:31.911354200Z",
     "start_time": "2024-02-20T00:53:31.862343600Z"
    }
   },
   "id": "1da659db6aef7e03",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[   134,   1488,   1208,  45102,  43648,   1988,  18220,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0],\n       [  1224,      0,     33,    663,    122,   2622,   2151,  42010,\n          3199,  25792,   1369,   9438,  26509,   9196,  37384,  11499,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0],\n       [ 71953,   2929,   5341,   8097,    614,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0],\n       [ 16250,   1872,    891,  33417,   1843,   2739,   1858,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0],\n       [ 11496,  40826,  69677,   2495,  17829,   9101,  38865,  58363,\n        214862,  27910,   4875,   1253,    436,  63210,   1091,  28660,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_X_test[:5, :]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:31.913355100Z",
     "start_time": "2024-02-20T00:53:31.894350600Z"
    }
   },
   "id": "859217e5388d9262",
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modeling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c6c031b0c35327b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "train_label_tensor = torch.tensor(np.array(y_train))\n",
    "valid_label_tensor = torch.tensor(np.array(y_valid))\n",
    "test_label_tensor = torch.tensor(np.array(y_test))\n",
    "print(train_label_tensor[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:31.972872100Z",
     "start_time": "2024-02-20T00:53:31.910354100Z"
    }
   },
   "id": "5e5f3b9e393d1ee8",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "\n",
    "class TextCNNLightning(L.LightningModule):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout, train_batch_size):\n",
    "        super().__init__()\n",
    "        self.lr = None\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(fs, embedding_dim))\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # text = [batch size, sent len]\n",
    "        embedded = self.embedding(text)  # embedded = [batch size, sent len, emb dim]\n",
    "        embedded = embedded.unsqueeze(1)  # embedded = [batch size, 1, sent len, emb dim]\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "        # conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        # pooled_n = [batch size, n_filters]\n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "        # cat = [batch size, n_filters * len(filter_sizes)]\n",
    "        return self.fc(cat)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Get inputs and labels\n",
    "        inputs, labels = batch\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = self(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "        # Log loss\n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "        # Return loss\n",
    "        return loss\n",
    "\n",
    "    def __accuracy(self, outputs, labels):\n",
    "        predictions = outputs.argmax(dim=1)  # Get indices of highest probability\n",
    "        correct = (predictions == labels).sum().item()\n",
    "        acc = correct / len(labels)\n",
    "        return acc\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Get inputs and labels\n",
    "        inputs, labels = batch\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = self(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        acc = self.__accuracy(outputs, labels)\n",
    "\n",
    "        # Log loss and accuracy\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", acc)\n",
    "\n",
    "        # Return loss and accuracy\n",
    "        return loss, acc\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Get inputs and labels\n",
    "        inputs, labels = batch\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = self(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        acc = self.__accuracy(outputs, labels)\n",
    "\n",
    "        # Log loss and accuracy\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", acc)\n",
    "\n",
    "        # Return loss and accuracy\n",
    "        return loss, acc\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        encoded_train = torch.tensor(padded_X_train).to(torch.int32)\n",
    "        train_dataset = torch.utils.data.TensorDataset(encoded_train, train_label_tensor)\n",
    "        train_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle=True, num_workers=7,\n",
    "                                                       persistent_workers=True, batch_size=self.train_batch_size)\n",
    "        return train_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        encoded_valid = torch.tensor(padded_X_valid).to(torch.int32)\n",
    "        valid_dataset = torch.utils.data.TensorDataset(encoded_valid, valid_label_tensor)\n",
    "        valid_dataloader = torch.utils.data.DataLoader(valid_dataset, shuffle=False, batch_size=1, num_workers=7,\n",
    "                                                       persistent_workers=True)\n",
    "        return valid_dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        encoded_test = torch.tensor(padded_X_test).to(torch.int32)\n",
    "        test_dataset = torch.utils.data.TensorDataset(encoded_test, test_label_tensor)\n",
    "        test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=False, batch_size=1, num_workers=7)\n",
    "        return test_dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:59:36.681751100Z",
     "start_time": "2024-02-20T00:59:36.646742600Z"
    }
   },
   "id": "4982a56064326190",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# HPO using optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter space\n",
    "    embedding_dim = trial.suggest_int(\"embedding_dim\", 100, 500)\n",
    "    n_filters = trial.suggest_int(\"n_filters\", 100, 300)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', .1, .9)\n",
    "\n",
    "    # Suggest a logarithmic value\n",
    "    log_base_2_value = trial.suggest_int('log_base_2_value', 0, 10)\n",
    "    # Convert to actual value\n",
    "    train_batch_size = 2 ** log_base_2_value\n",
    "\n",
    "    # Initialize the model with the hyperparameters\n",
    "    model = TextCNNLightning(vocab_size=vocab_size, embedding_dim=embedding_dim, n_filters=n_filters,\n",
    "                             filter_sizes=[3, 4, 5], output_dim=2, dropout=dropout_rate,\n",
    "                             train_batch_size=train_batch_size)\n",
    "\n",
    "    # Trainer settings\n",
    "    trainer = L.Trainer(\n",
    "        accelerator=\"cpu\", max_epochs=15\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(model)\n",
    "\n",
    "    # Evaluate the model performance\n",
    "    return trainer.callback_metrics[\"train_loss\"]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:59:37.906866200Z",
     "start_time": "2024-02-20T00:59:37.884527900Z"
    }
   },
   "id": "48e71695ade82ad0",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-20 09:59:39,218] A new study created in memory with name: no-name-9007baf9-4c7d-43ea-8480-65dc51550d54\n",
      "GPU available: False, used: False\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | embedding | Embedding  | 2.7 M \n",
      "1 | convs     | ModuleList | 259 K \n",
      "2 | fc        | Linear     | 1.2 K \n",
      "3 | dropout   | Dropout    | 0     \n",
      "-----------------------------------------\n",
      "2.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.9 M     Total params\n",
      "11.788    Total estimated model params size (MB)\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | embedding | Embedding  | 2.7 M \n",
      "1 | convs     | ModuleList | 259 K \n",
      "2 | fc        | Linear     | 1.2 K \n",
      "3 | dropout   | Dropout    | 0     \n",
      "-----------------------------------------\n",
      "2.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.9 M     Total params\n",
      "11.788    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1efc1b4b4e294835a46457fe65aaed08"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksid\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:558: UserWarning: This DataLoader will create 7 worker processes in total. Our suggested max number of worker in current system is 6 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "[W 2024-02-20 09:59:42,804] Trial 0 failed with parameters: {'embedding_dim': 110, 'n_filters': 196, 'dropout_rate': 0.41145273798127213, 'log_base_2_value': 8} because of the following error: IndexError('index out of range in self').\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aksid\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\aksid\\AppData\\Local\\Temp\\ipykernel_14504\\199782948.py\", line 25, in objective\n",
      "    trainer.fit(model)\n",
      "  File \"C:\\Users\\aksid\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py\", line 543, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"C:\\Users\\aksid\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\aksid\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py\", line 579, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"C:\\Users\\aksid\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py\", line 986, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"C:\\Users\\aksid\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py\", line 1030, in _run_stage\n",
      "    self._run_sanity_check()\n",
      "  File \"C:\\Users\\aksid\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py\", line 1059, in _run_sanity_check\n",
      "    val_loop.run()\n",
      "  File \"C:\\Users\\aksid\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\loops\\utilities.py\", line 182, in _decorator\n",
      "    return loop_run(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\aksid\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py\", line 135, in run\n",
      "    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n",
      "  File \"C:\\Users\\aksid\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py\", line 396, in _evaluation_step\n",
      "    output = call._call_strategy_hook(trainer, hook_name, *step_args)\n",
      "  File \"C:\\Users\\aksid\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\aksid\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py\", line 412, in validation_step\n",
      "    return self.lightning_module.validation_step(*args, **kwargs)\n",
      "  File \"C:\\Users\\aksid\\AppData\\Local\\Temp\\ipykernel_14504\\783608278.py\", line 61, in validation_step\n",
      "    outputs = self(inputs)\n",
      "  File \"C:\\Users\\aksid\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\aksid\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\aksid\\AppData\\Local\\Temp\\ipykernel_14504\\783608278.py\", line 19, in forward\n",
      "    embedded = self.embedding(text)  # embedded = [batch size, sent len, emb dim]\n",
      "  File \"C:\\Users\\aksid\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\aksid\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\aksid\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\", line 163, in forward\n",
      "    return F.embedding(\n",
      "  File \"C:\\Users\\aksid\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\torch\\nn\\functional.py\", line 2237, in embedding\n",
      "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
      "IndexError: index out of range in self\n",
      "[W 2024-02-20 09:59:42,805] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[38], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Create a study object\u001B[39;00m\n\u001B[0;32m      4\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study()  \u001B[38;5;66;03m# or 'maximize' based on your goal\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Specify the number of trials\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Print the best hyperparameters\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest trial: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstudy\u001B[38;5;241m.\u001B[39mbest_trial\u001B[38;5;241m.\u001B[39mparams\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\optuna\\study\\study.py:451\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    348\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[0;32m    349\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    350\u001B[0m     func: ObjectiveFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    357\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    358\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    359\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[0;32m    360\u001B[0m \n\u001B[0;32m    361\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    449\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[0;32m    450\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 451\u001B[0m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    452\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    453\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    454\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    455\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    456\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    458\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    459\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    461\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001B[0m, in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 66\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     76\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     79\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    160\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 163\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[0;32m    166\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[0;32m    169\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    244\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    247\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[0;32m    248\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[0;32m    250\u001B[0m ):\n\u001B[1;32m--> 251\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[0;32m    199\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 200\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    202\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[0;32m    203\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[1;32mIn[37], line 25\u001B[0m, in \u001B[0;36mobjective\u001B[1;34m(trial)\u001B[0m\n\u001B[0;32m     20\u001B[0m trainer \u001B[38;5;241m=\u001B[39m L\u001B[38;5;241m.\u001B[39mTrainer(\n\u001B[0;32m     21\u001B[0m     accelerator\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m, max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m15\u001B[39m\n\u001B[0;32m     22\u001B[0m )\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m---> 25\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m# Evaluate the model performance\u001B[39;00m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mcallback_metrics[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_loss\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:543\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    541\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[0;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 543\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    544\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[0;32m    545\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[1;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m trainer_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[0;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:579\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    572\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    573\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[0;32m    574\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[0;32m    575\u001B[0m     ckpt_path,\n\u001B[0;32m    576\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    577\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    578\u001B[0m )\n\u001B[1;32m--> 579\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    581\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[0;32m    582\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:986\u001B[0m, in \u001B[0;36mTrainer._run\u001B[1;34m(self, model, ckpt_path)\u001B[0m\n\u001B[0;32m    981\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n\u001B[0;32m    983\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m    984\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[0;32m    985\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m--> 986\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    988\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m    989\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[0;32m    990\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m    991\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1030\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1028\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining:\n\u001B[0;32m   1029\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m isolate_rng():\n\u001B[1;32m-> 1030\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_sanity_check\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1031\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n\u001B[0;32m   1032\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_loop\u001B[38;5;241m.\u001B[39mrun()\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1059\u001B[0m, in \u001B[0;36mTrainer._run_sanity_check\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1056\u001B[0m call\u001B[38;5;241m.\u001B[39m_call_callback_hooks(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_sanity_check_start\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1058\u001B[0m \u001B[38;5;66;03m# run eval step\u001B[39;00m\n\u001B[1;32m-> 1059\u001B[0m \u001B[43mval_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1061\u001B[0m call\u001B[38;5;241m.\u001B[39m_call_callback_hooks(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_sanity_check_end\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1063\u001B[0m \u001B[38;5;66;03m# reset logger connector\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\loops\\utilities.py:182\u001B[0m, in \u001B[0;36m_no_grad_context.<locals>._decorator\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    180\u001B[0m     context_manager \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mno_grad\n\u001B[0;32m    181\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context_manager():\n\u001B[1;32m--> 182\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loop_run(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:135\u001B[0m, in \u001B[0;36m_EvaluationLoop.run\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    133\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mis_last_batch \u001B[38;5;241m=\u001B[39m data_fetcher\u001B[38;5;241m.\u001B[39mdone\n\u001B[0;32m    134\u001B[0m     \u001B[38;5;66;03m# run step hooks\u001B[39;00m\n\u001B[1;32m--> 135\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_evaluation_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[0;32m    137\u001B[0m     \u001B[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001B[39;00m\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:396\u001B[0m, in \u001B[0;36m_EvaluationLoop._evaluation_step\u001B[1;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001B[0m\n\u001B[0;32m    390\u001B[0m hook_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_step\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mtesting \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation_step\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    391\u001B[0m step_args \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    392\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001B[0;32m    393\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m using_dataloader_iter\n\u001B[0;32m    394\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m (dataloader_iter,)\n\u001B[0;32m    395\u001B[0m )\n\u001B[1;32m--> 396\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_strategy_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhook_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mstep_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    398\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mincrement_processed()\n\u001B[0;32m    400\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m using_dataloader_iter:\n\u001B[0;32m    401\u001B[0m     \u001B[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:309\u001B[0m, in \u001B[0;36m_call_strategy_hook\u001B[1;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n\u001B[0;32m    306\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Strategy]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 309\u001B[0m     output \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    311\u001B[0m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n\u001B[0;32m    312\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m prev_fx_name\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:412\u001B[0m, in \u001B[0;36mStrategy.validation_step\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    410\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module:\n\u001B[0;32m    411\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_redirection(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation_step\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 412\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module\u001B[38;5;241m.\u001B[39mvalidation_step(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "Cell \u001B[1;32mIn[36], line 61\u001B[0m, in \u001B[0;36mTextCNNLightning.validation_step\u001B[1;34m(self, batch, batch_idx)\u001B[0m\n\u001B[0;32m     58\u001B[0m inputs, labels \u001B[38;5;241m=\u001B[39m batch\n\u001B[0;32m     60\u001B[0m \u001B[38;5;66;03m# Forward pass\u001B[39;00m\n\u001B[1;32m---> 61\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;66;03m# Calculate loss\u001B[39;00m\n\u001B[0;32m     64\u001B[0m loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mcross_entropy(outputs, labels)\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[36], line 19\u001B[0m, in \u001B[0;36mTextCNNLightning.forward\u001B[1;34m(self, text)\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, text):\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;66;03m# text = [batch size, sent len]\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m     embedded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# embedded = [batch size, sent len, emb dim]\u001B[39;00m\n\u001B[0;32m     20\u001B[0m     embedded \u001B[38;5;241m=\u001B[39m embedded\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# embedded = [batch size, 1, sent len, emb dim]\u001B[39;00m\n\u001B[0;32m     21\u001B[0m     conved \u001B[38;5;241m=\u001B[39m [F\u001B[38;5;241m.\u001B[39mrelu(conv(embedded))\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m3\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m conv \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvs]\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001B[0m, in \u001B[0;36mEmbedding.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 163\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    165\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\KoreanHateSpeechClassifier\\venv\\lib\\site-packages\\torch\\nn\\functional.py:2237\u001B[0m, in \u001B[0;36membedding\u001B[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[0;32m   2231\u001B[0m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[0;32m   2232\u001B[0m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[0;32m   2233\u001B[0m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[0;32m   2234\u001B[0m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[0;32m   2235\u001B[0m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[0;32m   2236\u001B[0m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[1;32m-> 2237\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mIndexError\u001B[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "# Create a study object\n",
    "study = optuna.create_study()  # or 'maximize' based on your goal\n",
    "study.optimize(objective, n_trials=100)  # Specify the number of trials\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f\"Best trial: {study.best_trial.params}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:59:43.208813200Z",
     "start_time": "2024-02-20T00:59:39.219622700Z"
    }
   },
   "id": "72974d1d37e941f3",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # model = TextCNNLightning(vocab_size=vocab_size, num_labels=len(set(y_train)), l=l)\n",
    "# model = TextCNNLightning(vocab_size=vocab_size, embedding_dim=300, n_filters=100,\n",
    "#                          filter_sizes=[3, 4, 5], output_dim=2, dropout=.5, train_batch_size=512)\n",
    "# model.to(device)\n",
    "# \n",
    "# vocab_size, len(set(y_train))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:37.789866400Z",
     "start_time": "2024-02-20T00:53:37.786865600Z"
    }
   },
   "id": "25a386b6247374ec",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b56c15924652389"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# %%time\n",
    "# \n",
    "# from lightning.pytorch.callbacks import LearningRateFinder\n",
    "# \n",
    "# trainer = L.Trainer(\n",
    "#     accelerator=\"auto\", devices=\"auto\", strategy=\"auto\",\n",
    "#     max_epochs=30, callbacks=[LearningRateFinder()]\n",
    "# )\n",
    "# trainer.fit(model=model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-20T00:53:37.787866100Z"
    }
   },
   "id": "9b5662c64c4bcf84",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# trainer.test()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-20T00:53:37.789866400Z"
    }
   },
   "id": "b2f03f95ce98269e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T00:53:37.806869900Z",
     "start_time": "2024-02-20T00:53:37.790866300Z"
    }
   },
   "id": "41ca4069c519ff53"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
