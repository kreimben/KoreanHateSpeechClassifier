{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Korean Hate Speech Classifier\n",
    "## Written by: [Jehwan Kim](github.com/kreimben)\n",
    "## Date: 19th Feb 2024\n",
    "## Referenced Paper: \n",
    "* [Convolutional Neural Networks for Sentence Classification](https://arxiv.org/abs/1408.5882)\n",
    "* [Cyclical Learning Rates for Training Neural Networks](https://arxiv.org/abs/1506.01186)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b85a589180c7304"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the word2vec model first,"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76142ca29aea3a03"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:54.050972Z",
     "start_time": "2024-02-20T02:24:52.008627Z"
    }
   },
   "id": "95ba83ff602bf2ae",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "### And then, load labeled data using pandas"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc778d92bb73c7c1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dev_df = pd.read_csv('./labeled/dev.tsv', sep='\\t')\n",
    "train_df = pd.read_csv('./labeled/train.tsv', sep='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:54.102416Z",
     "start_time": "2024-02-20T02:24:54.048731Z"
    }
   },
   "id": "483cddf9b1ef8ff5",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                            comments  contain_gender_bias  \\\n0  (현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...                False   \n1  ....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...                False   \n2  ...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...                False   \n3                 1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데                False   \n4  1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...                 True   \n\n     bias  hate  \n0  others  hate  \n1    none  none  \n2    none  hate  \n3    none  none  \n4  gender  hate  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comments</th>\n      <th>contain_gender_bias</th>\n      <th>bias</th>\n      <th>hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...</td>\n      <td>False</td>\n      <td>others</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...</td>\n      <td>False</td>\n      <td>none</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...</td>\n      <td>False</td>\n      <td>none</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데</td>\n      <td>False</td>\n      <td>none</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...</td>\n      <td>True</td>\n      <td>gender</td>\n      <td>hate</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:54.103032Z",
     "start_time": "2024-02-20T02:24:54.071573Z"
    }
   },
   "id": "957b5d894af019aa",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                            comments  contain_gender_bias  \\\n0                        송중기 시대극은 믿고본다. 첫회 신선하고 좋았다.                False   \n1                                            지현우 나쁜놈                False   \n2         알바쓰고많이만들면되지 돈욕심없으면골목식당왜나온겨 기댕기게나하고 산에가서팔어라                False   \n3                                   설마 ㅈ 현정 작가 아니지??                 True   \n4  이미자씨 송혜교씨 돈이 그리 많으면 탈세말고 그돈으로 평소에 불우이웃에게 기부도 좀...                False   \n\n     bias       hate  \n0    none       none  \n1    none  offensive  \n2    none       hate  \n3  gender       hate  \n4    none  offensive  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comments</th>\n      <th>contain_gender_bias</th>\n      <th>bias</th>\n      <th>hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>송중기 시대극은 믿고본다. 첫회 신선하고 좋았다.</td>\n      <td>False</td>\n      <td>none</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>지현우 나쁜놈</td>\n      <td>False</td>\n      <td>none</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>알바쓰고많이만들면되지 돈욕심없으면골목식당왜나온겨 기댕기게나하고 산에가서팔어라</td>\n      <td>False</td>\n      <td>none</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>설마 ㅈ 현정 작가 아니지??</td>\n      <td>True</td>\n      <td>gender</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>이미자씨 송혜교씨 돈이 그리 많으면 탈세말고 그돈으로 평소에 불우이웃에게 기부도 좀...</td>\n      <td>False</td>\n      <td>none</td>\n      <td>offensive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:54.104325Z",
     "start_time": "2024-02-20T02:24:54.080505Z"
    }
   },
   "id": "6998e4faa8a15643",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### In `hate` column, `offensive`, `none`, `hate`.\n",
    "### In `contain_gender_bias` column, `True`, `False`.\n",
    "### In `bias` column, `none`, `gender`, `others`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f3074856f112f7c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                               comments  contain_gender_bias  \\\n3563  부동산 업자의 알았을거다.이 한마디에 대성 평생 이룬 커리어를 무너트릴려고? 생각좀...                False   \n1773                         꼭 트와 찐팬 아닌것들이 맨날 더 광분하더라 ㅉ                False   \n5271  역겨워. 더러워. 저번에 걸렸을때 수사만 제대로 했으면 다음 피해자는 없었을텐데.....                False   \n7477                                         진짜 이쁘긴 이쁘다                False   \n1477                                            근데 어쩔??                False   \n\n        bias       hate  \n3563    none       hate  \n1773  others  offensive  \n5271  others       hate  \n7477    none       none  \n1477    none  offensive  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comments</th>\n      <th>contain_gender_bias</th>\n      <th>bias</th>\n      <th>hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3563</th>\n      <td>부동산 업자의 알았을거다.이 한마디에 대성 평생 이룬 커리어를 무너트릴려고? 생각좀...</td>\n      <td>False</td>\n      <td>none</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>1773</th>\n      <td>꼭 트와 찐팬 아닌것들이 맨날 더 광분하더라 ㅉ</td>\n      <td>False</td>\n      <td>others</td>\n      <td>offensive</td>\n    </tr>\n    <tr>\n      <th>5271</th>\n      <td>역겨워. 더러워. 저번에 걸렸을때 수사만 제대로 했으면 다음 피해자는 없었을텐데.....</td>\n      <td>False</td>\n      <td>others</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>7477</th>\n      <td>진짜 이쁘긴 이쁘다</td>\n      <td>False</td>\n      <td>none</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>1477</th>\n      <td>근데 어쩔??</td>\n      <td>False</td>\n      <td>none</td>\n      <td>offensive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine train and dev data.\n",
    "df = pd.concat([dev_df, train_df], ignore_index=True)\n",
    "df.sample(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:54.106562Z",
     "start_time": "2024-02-20T02:24:54.083371Z"
    }
   },
   "id": "57a62ec519832594",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(hate\n none         3646\n offensive    2688\n hate         2033\n Name: count, dtype: int64,\n contain_gender_bias\n False    404\n True      67\n Name: count, dtype: int64,\n bias\n none      342\n gender     67\n others     62\n Name: count, dtype: int64)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.hate.value_counts(), dev_df.contain_gender_bias.value_counts(), dev_df.bias.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:54.115750Z",
     "start_time": "2024-02-20T02:24:54.089387Z"
    }
   },
   "id": "adc2696d1f6809b2",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load words data and tokeniser from past project."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48640b0cad2eddfe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('tokenizer.pkl', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "with open('words.pkl', 'rb') as handle:\n",
    "    words = pickle.load(handle)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:55.233008Z",
     "start_time": "2024-02-20T02:24:54.092093Z"
    }
   },
   "id": "c309aefe176e427a",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def tokenize(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    preprocess = lambda x: [w for w in x if w not in STOP_WORDS]\n",
    "    return preprocess(tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:55.246603Z",
     "start_time": "2024-02-20T02:24:55.233840Z"
    }
   },
   "id": "3d3dbea551c4ae89",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "('미애가 이쁘긴해', ['미애', '이쁘긴', '해'])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df.sample(1).comments.values[0]\n",
    "\n",
    "sample, tokenize(sample)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:55.247771Z",
     "start_time": "2024-02-20T02:24:55.240396Z"
    }
   },
   "id": "32c7deac9d238855",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yk/hzm_ywr95w3gr1cvnlndq5_r0000gn/T/ipykernel_96054/1445675357.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['hate'] = df['hate'].replace(['none', 'offensive', 'hate'], [0, 1, 1])\n",
      "/var/folders/yk/hzm_ywr95w3gr1cvnlndq5_r0000gn/T/ipykernel_96054/1445675357.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['contain_gender_bias'] = df['contain_gender_bias'].replace([True, False], [1, 0])\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                            comments  contain_gender_bias  \\\n0                        송중기 시대극은 믿고본다. 첫회 신선하고 좋았다.                    0   \n1                                            지현우 나쁜놈                    0   \n2         알바쓰고많이만들면되지 돈욕심없으면골목식당왜나온겨 기댕기게나하고 산에가서팔어라                    0   \n3                                   설마 ㅈ 현정 작가 아니지??                    1   \n4  이미자씨 송혜교씨 돈이 그리 많으면 탈세말고 그돈으로 평소에 불우이웃에게 기부도 좀...                    0   \n\n     bias  hate                                             tokens  \n0    none     0              [송중기, 시대, 극은, 믿고, 본다., 첫회, 신선, 았다, .]  \n1    none     1                                         [지현우, 나쁜놈]  \n2    none     1  [알바, 쓰고, 많이, 만들면, 되지, 돈, 욕심, 으면, 골목, 식당, 왜나온겨,...  \n3  gender     1                                    [ㅈ, 현정, 작가, ??]  \n4    none     1  [이미자, 송혜교, 돈이, 그리, 으면, 탈세, 말고, 그돈, 평소, 불우이웃, 기...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comments</th>\n      <th>contain_gender_bias</th>\n      <th>bias</th>\n      <th>hate</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>송중기 시대극은 믿고본다. 첫회 신선하고 좋았다.</td>\n      <td>0</td>\n      <td>none</td>\n      <td>0</td>\n      <td>[송중기, 시대, 극은, 믿고, 본다., 첫회, 신선, 았다, .]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>지현우 나쁜놈</td>\n      <td>0</td>\n      <td>none</td>\n      <td>1</td>\n      <td>[지현우, 나쁜놈]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>알바쓰고많이만들면되지 돈욕심없으면골목식당왜나온겨 기댕기게나하고 산에가서팔어라</td>\n      <td>0</td>\n      <td>none</td>\n      <td>1</td>\n      <td>[알바, 쓰고, 많이, 만들면, 되지, 돈, 욕심, 으면, 골목, 식당, 왜나온겨,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>설마 ㅈ 현정 작가 아니지??</td>\n      <td>1</td>\n      <td>gender</td>\n      <td>1</td>\n      <td>[ㅈ, 현정, 작가, ??]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>이미자씨 송혜교씨 돈이 그리 많으면 탈세말고 그돈으로 평소에 불우이웃에게 기부도 좀...</td>\n      <td>0</td>\n      <td>none</td>\n      <td>1</td>\n      <td>[이미자, 송혜교, 돈이, 그리, 으면, 탈세, 말고, 그돈, 평소, 불우이웃, 기...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = df['comments'].apply(tokenize)\n",
    "# 공격적인(offensive) 댓글 또한 혐오 데이터 셋으로 분류함.\n",
    "df['hate'] = df['hate'].replace(['none', 'offensive', 'hate'], [0, 1, 1])\n",
    "df['contain_gender_bias'] = df['contain_gender_bias'].replace([True, False], [1, 0])\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:56.161174Z",
     "start_time": "2024-02-20T02:24:55.301004Z"
    }
   },
   "id": "da709590362b1e96",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for sentence in df.tokens:\n",
    "    for word in sentence: vocab.add(word)\n",
    "\n",
    "vocab_size = len(vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:56.175077Z",
     "start_time": "2024-02-20T02:24:56.171431Z"
    }
   },
   "id": "b281c2177fdf376",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vectorise"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7ef7501882fb09f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('vectorizer.pkl', 'rb') as handle:\n",
    "    vectorizer = pickle.load(handle)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:56.721945Z",
     "start_time": "2024-02-20T02:24:56.173714Z"
    }
   },
   "id": "5b6238857638d8c2",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encoding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9a0973672e14a64"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0         [13834, 366, 55661, 671, 1342, 16079, 423, 432]\n1                                                  [6021]\n2       [750, 384, 2886, 332, 1898, 10604, 3279, 21690...\n3                               [1990, 1092, 75890, 9257]\n4       [84631, 533, 15596, 533, 454, 171, 779, 5641, ...\n                              ...                        \n8362                                        [2805, 11384]\n8363                       [2805, 7442, 3105, 3781, 3744]\n8364              [46019, 1577, 58, 591, 1505, 22957, 58]\n8365    [4232, 882, 75943, 769, 4678, 887, 22943, 4270...\n8366       [396, 1469, 1727, 36544, 1694, 30, 3644, 5144]\nName: encoding, Length: 8367, dtype: object"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['encoding'] = df['comments'].apply(vectorizer.encode_a_doc_to_list)\n",
    "df.encoding"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:57.356243Z",
     "start_time": "2024-02-20T02:24:56.720481Z"
    }
   },
   "id": "ae2f4030b420969e",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate\n",
      "1    4721\n",
      "0    3646\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "(8367, 8367, True)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = df['encoding']\n",
    "y_data = df['hate']\n",
    "print(y_data.value_counts())\n",
    "len(X_data), len(y_data), len(X_data) == len(y_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:57.358877Z",
     "start_time": "2024-02-20T02:24:57.355666Z"
    }
   },
   "id": "abc1b33996c85487",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "hate\n1    3824\n0    2953\nName: count, dtype: int64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=.1, random_state=0, stratify=y_data)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=.1, random_state=0, stratify=y_train)\n",
    "\n",
    "y_train.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:57.508458Z",
     "start_time": "2024-02-20T02:24:57.358974Z"
    }
   },
   "id": "aea73a715225d891",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공격적인(offensive) 댓글 또한 혐오 데이터 셋으로 분류함.\n",
      "--------훈련 데이터의 비율-----------\n",
      "혐오 댓글 = 56.426%\n",
      "일반 댓글 = 43.574%\n",
      "--------검증 데이터의 비율-----------\n",
      "혐오 댓글 = 56.441%\n",
      "일반 댓글 = 43.559%\n",
      "--------테스트 데이터의 비율-----------\n",
      "혐오 댓글 = 56.392%\n",
      "일반 댓글 = 43.608%\n"
     ]
    }
   ],
   "source": [
    "print('공격적인(offensive) 댓글 또한 혐오 데이터 셋으로 분류함.')\n",
    "print('--------훈련 데이터의 비율-----------')\n",
    "print(f'혐오 댓글 = {round(y_train.value_counts()[1] / len(y_train) * 100, 3)}%')\n",
    "print(f'일반 댓글 = {round(y_train.value_counts()[0] / len(y_train) * 100, 3)}%')\n",
    "print('--------검증 데이터의 비율-----------')\n",
    "print(f'혐오 댓글 = {round(y_valid.value_counts()[1] / len(y_valid) * 100, 3)}%')\n",
    "print(f'일반 댓글 = {round(y_valid.value_counts()[0] / len(y_valid) * 100, 3)}%')\n",
    "print('--------테스트 데이터의 비율-----------')\n",
    "print(f'혐오 댓글 = {round(y_test.value_counts()[1] / len(y_test) * 100, 3)}%')\n",
    "print(f'일반 댓글 = {round(y_test.value_counts()[0] / len(y_test) * 100, 3)}%')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:57.515121Z",
     "start_time": "2024-02-20T02:24:57.510090Z"
    }
   },
   "id": "636c107f5616018a",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Padding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc3cc8cad19abafc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "댓글의 최대 길이 : 39\n",
      "댓글의 평균 길이 : 9.449018739855394\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('댓글의 최대 길이 :', max(len(review) for review in X_train))\n",
    "print('댓글의 평균 길이 :', sum(map(len, X_train)) / len(X_train))\n",
    "plt.hist([len(review) for review in X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:57.703383Z",
     "start_time": "2024-02-20T02:24:57.519110Z"
    }
   },
   "id": "c9771b28e6e289d0",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "max_len = max(len(review) for review in X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:57.729396Z",
     "start_time": "2024-02-20T02:24:57.668948Z"
    }
   },
   "id": "5e299ce12a3f55b8",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 길이가 길지 않아서 그냥 최대값 그대로 진행합니다. (패딩)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce876dd87ee220ea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def pad_sequences(sentences: [[int]], max_len: int) -> np.ndarray:\n",
    "    features = np.zeros((len(sentences), max_len), dtype=int)\n",
    "    for index, sentence in enumerate(sentences):\n",
    "        if len(sentence) != 0:\n",
    "            features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
    "    return features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:57.747683Z",
     "start_time": "2024-02-20T02:24:57.673605Z"
    }
   },
   "id": "f31851242ee3396a",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 크기 : (6777, 39)\n",
      "검증 데이터의 크기 : (753, 39)\n",
      "테스트 데이터의 크기 : (837, 39)\n"
     ]
    }
   ],
   "source": [
    "padded_X_train = pad_sequences(X_train, max_len=max_len)\n",
    "padded_X_valid = pad_sequences(X_valid, max_len=max_len)\n",
    "padded_X_test = pad_sequences(X_test, max_len=max_len)\n",
    "\n",
    "print('훈련 데이터의 크기 :', padded_X_train.shape)\n",
    "print('검증 데이터의 크기 :', padded_X_valid.shape)\n",
    "print('테스트 데이터의 크기 :', padded_X_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:57.749823Z",
     "start_time": "2024-02-20T02:24:57.676522Z"
    }
   },
   "id": "1da659db6aef7e03",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[   134,   1488,   1208,  45102,  43648,   1988,  18220,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0],\n       [  1224,      0,     33,    663,    122,   2622,   2151,  42010,\n          3199,  25792,   1369,   9438,  26509,   9196,  37384,  11499,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0],\n       [ 71953,   2929,   5341,   8097,    614,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0],\n       [ 16250,   1872,    891,  33417,   1843,   2739,   1858,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0],\n       [ 11496,  40826,  69677,   2495,  17829,   9101,  38865,  58363,\n        214862,  27910,   4875,   1253,    436,  63210,   1091,  28660,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0]])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_X_test[:5, :]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:57.751661Z",
     "start_time": "2024-02-20T02:24:57.687621Z"
    }
   },
   "id": "859217e5388d9262",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modeling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c6c031b0c35327b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "train_label_tensor = torch.tensor(np.array(y_train))\n",
    "valid_label_tensor = torch.tensor(np.array(y_valid))\n",
    "test_label_tensor = torch.tensor(np.array(y_test))\n",
    "print(train_label_tensor[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:57.836674Z",
     "start_time": "2024-02-20T02:24:57.691426Z"
    }
   },
   "id": "5e5f3b9e393d1ee8",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TextCNNLightning(L.LightningModule):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout, train_batch_size):\n",
    "        super().__init__()\n",
    "        self.lr = None\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(fs, embedding_dim))\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # text = [batch size, sent len]\n",
    "        embedded = self.embedding(text)  # embedded = [batch size, sent len, emb dim]\n",
    "        embedded = embedded.unsqueeze(1)  # embedded = [batch size, 1, sent len, emb dim]\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "        # conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        # pooled_n = [batch size, n_filters]\n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "        # cat = [batch size, n_filters * len(filter_sizes)]\n",
    "        return self.fc(cat)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Get inputs and labels\n",
    "        inputs, labels = batch\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = self(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "        # Log loss\n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "        # Return loss\n",
    "        return loss\n",
    "\n",
    "    def __accuracy(self, outputs, labels):\n",
    "        predictions = outputs.argmax(dim=1)  # Get indices of highest probability\n",
    "        correct = (predictions == labels).sum().item()\n",
    "        acc = correct / len(labels)\n",
    "        return acc\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Get inputs and labels\n",
    "        inputs, labels = batch\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = self(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        acc = self.__accuracy(outputs, labels)\n",
    "\n",
    "        # Log loss and accuracy\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", acc)\n",
    "\n",
    "        # Return loss and accuracy\n",
    "        return loss, acc\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Get inputs and labels\n",
    "        inputs, labels = batch\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = self(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        acc = self.__accuracy(outputs, labels)\n",
    "\n",
    "        # Log loss and accuracy\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", acc)\n",
    "\n",
    "        # Return loss and accuracy\n",
    "        return loss, acc\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        encoded_train = torch.tensor(padded_X_train).to(torch.int32)\n",
    "        train_dataset = TensorDataset(encoded_train, train_label_tensor)\n",
    "        train_dataloader = DataLoader(train_dataset, shuffle=True, num_workers=7,\n",
    "                                      persistent_workers=True, batch_size=self.train_batch_size)\n",
    "        return train_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        encoded_valid = torch.tensor(padded_X_valid).to(torch.int32)\n",
    "        valid_dataset = TensorDataset(encoded_valid, valid_label_tensor)\n",
    "        valid_dataloader = DataLoader(valid_dataset, shuffle=False, batch_size=1, num_workers=7,\n",
    "                                      persistent_workers=True)\n",
    "        return valid_dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        encoded_test = torch.tensor(padded_X_test).to(torch.int32)\n",
    "        test_dataset = TensorDataset(encoded_test, test_label_tensor)\n",
    "        test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=1, num_workers=7)\n",
    "        return test_dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:57.839798Z",
     "start_time": "2024-02-20T02:24:57.697811Z"
    }
   },
   "id": "4982a56064326190",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # HPO using optuna\n",
    "# \n",
    "# def objective(trial):\n",
    "#     # Define the hyperparameter space\n",
    "#     embedding_dim = trial.suggest_int(\"embedding_dim\", 100, 500)\n",
    "#     n_filters = trial.suggest_int(\"n_filters\", 100, 300)\n",
    "#     dropout_rate = trial.suggest_float('dropout_rate', .1, .9)\n",
    "# \n",
    "#     # Suggest a logarithmic value\n",
    "#     log_base_2_value = trial.suggest_int('log_base_2_value', 0, 10)\n",
    "#     # Convert to actual value\n",
    "#     train_batch_size = 2 ** log_base_2_value\n",
    "# \n",
    "#     # Initialize the model with the hyperparameters\n",
    "#     model = TextCNNLightning(vocab_size=vocab_size, embedding_dim=embedding_dim, n_filters=n_filters,\n",
    "#                              filter_sizes=[3, 4, 5], output_dim=2, dropout=dropout_rate,\n",
    "#                              train_batch_size=train_batch_size)\n",
    "# \n",
    "#     # Trainer settings\n",
    "#     trainer = L.Trainer(\n",
    "#         accelerator=\"auto\", max_epochs=15\n",
    "#     )\n",
    "# \n",
    "#     # Train the model\n",
    "#     trainer.fit(model)\n",
    "# \n",
    "#     # Evaluate the model performance\n",
    "#     return trainer.callback_metrics[\"train_loss\"]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:57.840439Z",
     "start_time": "2024-02-20T02:24:57.709093Z"
    }
   },
   "id": "48e71695ade82ad0",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# \n",
    "# # Create a study object\n",
    "# study = optuna.create_study()  # or 'maximize' based on your goal\n",
    "# study.optimize(objective, n_trials=100)  # Specify the number of trials\n",
    "# \n",
    "# # Print the best hyperparameters\n",
    "# print(f\"Best trial: {study.best_trial.params}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:57.841001Z",
     "start_time": "2024-02-20T02:24:57.711531Z"
    }
   },
   "id": "72974d1d37e941f3",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(24423, 2)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = TextCNNLightning(vocab_size=vocab_size, num_labels=len(set(y_train)), l=l)\n",
    "model = TextCNNLightning(vocab_size=vocab_size, embedding_dim=300, n_filters=100,\n",
    "                         filter_sizes=[3, 4, 5], output_dim=2, dropout=.5, train_batch_size=512)\n",
    "\n",
    "vocab_size, len(set(y_train))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T02:24:57.862269Z",
     "start_time": "2024-02-20T02:24:57.714712Z"
    }
   },
   "id": "25a386b6247374ec",
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b56c15924652389"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/kreimben/Repository/KoreanHateSpeechClassifier/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "Missing logger folder: /Users/kreimben/Repository/KoreanHateSpeechClassifier/lightning_logs\n",
      "/Users/kreimben/Repository/KoreanHateSpeechClassifier/venv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "44323df3af884ccc973afcce8ae035c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR finder stopped early after 91 steps due to diverging loss.\n",
      "Learning rate set to 0.006918309709189364\n",
      "Restoring states from the checkpoint path at /Users/kreimben/Repository/KoreanHateSpeechClassifier/.lr_find_7181f8c8-18a4-4bbe-a70c-3f9eb0d5b1c3.ckpt\n",
      "Restored all states from the checkpoint at /Users/kreimben/Repository/KoreanHateSpeechClassifier/.lr_find_7181f8c8-18a4-4bbe-a70c-3f9eb0d5b1c3.ckpt\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | embedding | Embedding  | 7.3 M \n",
      "1 | convs     | ModuleList | 360 K \n",
      "2 | fc        | Linear     | 602   \n",
      "3 | dropout   | Dropout    | 0     \n",
      "-----------------------------------------\n",
      "7.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.7 M     Total params\n",
      "30.751    Total estimated model params size (MB)\n",
      "Restored all states from the checkpoint at /Users/kreimben/Repository/KoreanHateSpeechClassifier/.lr_find_7181f8c8-18a4-4bbe-a70c-3f9eb0d5b1c3.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "112ec01bd51c4069b1d4772f682122a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "083c7def33cf4fea94193b70309ee337"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "43472b6d6a8d4a6fb87c144370f11607"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ecaf882bdcc40ce96137dfe467693c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d12b78fa1d7c40e9913e859550b04d08"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b49268186d04652a1516fad7e0a4943"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32b3180e1017421cbab4be7eb53e5b80"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca60ccd9595748388cfeaf616a21fb27"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "670022042ca24ba080b57d8d2bb114b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72587af43b4047d98a2037d5e862ba0d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48065cf4535740ef98584fd19f3b496a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.2 s, sys: 7.27 s, total: 32.5 s\n",
      "Wall time: 1h 45min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from lightning.pytorch.callbacks import LearningRateFinder\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"auto\", devices=\"auto\", strategy=\"auto\",\n",
    "    max_epochs=10, callbacks=[LearningRateFinder()]\n",
    ")\n",
    "trainer.fit(model=model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T04:10:56.161724Z",
     "start_time": "2024-02-20T02:24:57.839042Z"
    }
   },
   "id": "9b5662c64c4bcf84",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kreimben/Repository/KoreanHateSpeechClassifier/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at /Users/kreimben/Repository/KoreanHateSpeechClassifier/lightning_logs/version_0/checkpoints/epoch=9-step=133.ckpt\n",
      "Loaded model weights from the checkpoint at /Users/kreimben/Repository/KoreanHateSpeechClassifier/lightning_logs/version_0/checkpoints/epoch=9-step=133.ckpt\n",
      "/Users/kreimben/Repository/KoreanHateSpeechClassifier/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d191f7fcc29441c59dd94fa78a9cd85d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.6463560461997986\n",
      "        test_loss           0.7093809247016907\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'test_loss': 0.7093809247016907, 'test_acc': 0.6463560461997986}]"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T04:11:07.032350Z",
     "start_time": "2024-02-20T04:10:56.169004Z"
    }
   },
   "id": "b2f03f95ce98269e",
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using Bert to classificate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79089b972fa80692"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "from utils.evaluate import calculate_accuracy\n",
    "from transformers import BertModel\n",
    "\n",
    "\n",
    "class BertClassifier(L.LightningModule):\n",
    "    def __init__(self, n_classes: int, pretrained_model_name=\"klue/bert-base\", steps_per_epoch=None, n_epochs=None, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.bert = BertModel.from_pretrained(pretrained_model_name)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.n_epochs = n_epochs\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return self.classifier(output.pooler_output)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        \n",
    "        input_ids = input_ids.reshape(-1, input_ids.shape[-1])  # Keep last dimension dynamic\n",
    "        attention_mask = attention_mask.reshape(-1, attention_mask.shape[-1])\n",
    "        \n",
    "        outputs = self(input_ids, attention_mask)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Get inputs and labels\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        \n",
    "        input_ids = input_ids.reshape(-1, input_ids.shape[-1])  # Keep last dimension dynamic\n",
    "        attention_mask = attention_mask.reshape(-1, attention_mask.shape[-1])\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = self(input_ids, attention_mask)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        acc = calculate_accuracy(outputs, labels)\n",
    "\n",
    "        # Log loss and accuracy\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", acc)\n",
    "\n",
    "        # Return loss and accuracy\n",
    "        return loss, acc\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Get inputs and labels\n",
    "        input_ids, attention_mask, labels = batch\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = self(input_ids, attention_mask)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        acc = calculate_accuracy(outputs, labels)\n",
    "\n",
    "        # Log loss and accuracy\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", acc)\n",
    "\n",
    "        # Return loss and accuracy\n",
    "        return loss, acc\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=2e-5)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=self.steps_per_epoch * 0.1, gamma=0.1)\n",
    "        return [optimizer], [scheduler]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T06:47:14.351564Z",
     "start_time": "2024-02-20T06:47:14.315831Z"
    }
   },
   "id": "f55b3cbe769624ff",
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from utils.stopwords import STOP_WORDS\n",
    "\n",
    "dev_df = pd.read_csv('./labeled/dev.tsv', sep='\\t')\n",
    "train_df = pd.read_csv('./labeled/train.tsv', sep='\\t')\n",
    "df = pd.concat([dev_df, train_df], ignore_index=True)\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "bert_model = BertModel.from_pretrained(\"klue/bert-base\")\n",
    "tokenizer = BertTokenizer.from_pretrained('klue/bert-base')\n",
    "\n",
    "tokenized_batch = tokenizer.batch_encode_plus(df.comments.values, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "input_ids = tokenized_batch['input_ids']\n",
    "attention_mask = tokenized_batch['attention_mask']\n",
    "y_label_tensor = torch.tensor(np.array(y_data))\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_mask, y_label_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
    "train_dataloader, val_dataloader, test_dataloader = DataLoader(train_set, batch_size=32, shuffle=True), DataLoader(val_set, batch_size=32), DataLoader(test_set, batch_size=32)\n",
    "\n",
    "vocab_size = tokenizer.vocab_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T06:48:40.874578Z",
     "start_time": "2024-02-20T06:48:38.395814Z"
    }
   },
   "id": "c6522087995a23c9",
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type             | Params\n",
      "------------------------------------------------\n",
      "0 | bert       | BertModel        | 110 M \n",
      "1 | classifier | Linear           | 1.5 K \n",
      "2 | criterion  | CrossEntropyLoss | 0     \n",
      "------------------------------------------------\n",
      "110 M     Trainable params\n",
      "0         Non-trainable params\n",
      "110 M     Total params\n",
      "442.476   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4126a846ab8a4eb49057d51e03c68f45"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kreimben/Repository/KoreanHateSpeechClassifier/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/kreimben/Repository/KoreanHateSpeechClassifier/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f0869147ca045a38c40568c29d02290"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "550b4039dd58478a9d79e803d280321f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52256b286e1149fd879a8103de6f13bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b07c4628dbf4310aa0bccd007d0adf8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스화 및 훈련 파라미터 설정\n",
    "bert_classifier_model = BertClassifier(n_classes=2, steps_per_epoch=100, n_epochs=3)\n",
    "\n",
    "# 트레이너 설정 및 훈련 시작\n",
    "bert_trainer = L.Trainer(max_epochs=3)\n",
    "bert_trainer.fit(bert_classifier_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T07:00:43.942150Z",
     "start_time": "2024-02-20T06:48:40.874827Z"
    }
   },
   "id": "f6355ae9da6e7bf6",
   "execution_count": 123
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kreimben/Repository/KoreanHateSpeechClassifier/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at /Users/kreimben/Repository/KoreanHateSpeechClassifier/lightning_logs/version_16/checkpoints/epoch=2-step=549.ckpt\n",
      "Loaded model weights from the checkpoint at /Users/kreimben/Repository/KoreanHateSpeechClassifier/lightning_logs/version_16/checkpoints/epoch=2-step=549.ckpt\n",
      "/Users/kreimben/Repository/KoreanHateSpeechClassifier/venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "605f6b3261c64b2f91428ca5c32148e5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.7778662443161011\n",
      "        test_loss           0.7982401847839355\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'test_loss': 0.7982401847839355, 'test_acc': 0.7778662443161011}]"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_trainer.test(dataloaders=[test_dataloader])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T07:14:42.319697Z",
     "start_time": "2024-02-20T07:14:25.805662Z"
    }
   },
   "id": "89c5b202046732a2",
   "execution_count": 125
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 최종 결과\n",
    "\n",
    "* 이전 프로젝트인 word2vec에서 직접 가져온 tokeniser로 단어 임베딩을 진행한 결과 \n",
    "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
    "       Test metric             DataLoader 0\n",
    "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
    "        test_acc            0.6463560461997986\n",
    "        test_loss           0.7093809247016907\n",
    "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
    "정확도는 64%이고 손실률은 0.7이 됐다.\n",
    "손수 직접 임베딩을 한 것이라, 아무리 epoch를 더 돌린다 해도 정확도가 더 올라가지 않아 포기했다.\n",
    "HPO 관련 라이브러리를 설치해봤으나 시간이 너무 부족해 hpo는 하지 못했다.\n",
    "\n",
    "* bert에서 가져온 tokeniser로 단어 임베딜을 진행한 결과\n",
    "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
    "       Test metric             DataLoader 0\n",
    "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
    "        test_acc            0.7778662443161011\n",
    "        test_loss           0.7982401847839355\n",
    "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
    "정확도는 77%이고 손실률은 0.79이다.\n",
    "\n",
    "---\n",
    "\n",
    "프로젝트를 진행하면서 의문이였던 점은, 'tokeniser의 차이로 문장들의 전체 길이가 달라진다는 점이 최종 결과까지 영향을 줄 수 있는가'이다.\n",
    "또한 '이모티콘이나 자음을 이용해 ㅇㅁㅇ 이나 (ㅇㅅㅇ) 와 같은 것을 쓴다면 이 역시 stopword나 정규식을 이용해 필터링 해야하는가'이다.\n",
    "한국인들은 ㅋ 와 ㅋㅋ 의 의미를 다르게 받아들인다. 이럴 경우 tokenising 처리를 어디까지 해줘야 하는지가 관건인것 같다. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f07e7381a1b87b9f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
